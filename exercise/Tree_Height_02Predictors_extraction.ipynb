{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f370ebc8",
   "metadata": {},
   "source": [
    "# Estimation of tree height using GEDI dataset - Predictors extraction at point location"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d19f628",
   "metadata": {},
   "source": [
    "## 1.0 Reminder\n",
    "\n",
    "You need to access the dataset we will use in this notebook and later too.\n",
    "You already should have downloaded it and stored in the right folder, as follows:\n",
    "\n",
    "    cd ~/SE_data\n",
    "    git pull\n",
    "    rsync -hvrPt --ignore-existing ~/SE_data/* /media/sf_LVM_shared/my_SE_data\n",
    "    cd  /media/sf_LVM_shared/my_SE_data/exercise\n",
    "\n",
    "    pip3 install gdown # Google Drive access\n",
    "\n",
    "    [ -f tree_height.tar.gz ] || ~/.local/bin/gdown 1Y60EuLsfmTICTX-U_FxcE1odNAf04bd-\n",
    "    [ -d tree_height ] || tar xvf tree_height.tar.gz\n",
    "    \n",
    "Also, you should already installed `rasterio` package as follows:\n",
    "    \n",
    "    pip3 install rasterio\n",
    "    \n",
    "*Hint: you should never use `pip3` under `sudo`, else you could break your system-wide Python environment in very creative and subtle ways.* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8ede7a",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The main objectives of this tutorial is to show several ways how to extract pixel value at point location. \n",
    "\n",
    "We will use the files stored at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50196b07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree_height/txt/eu_x_y_height_predictors_select.txt\r\n",
      "tree_height/txt/eu_x_y_height_select.txt\r\n",
      "tree_height/txt/eu_x_y_predictors_select.txt\r\n",
      "tree_height/txt/eu_x_y_select.txt\r\n"
     ]
    }
   ],
   "source": [
    "! ls tree_height/txt/eu_x_y_*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41d3493",
   "metadata": {},
   "source": [
    "In particular we will reproduce this data-table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d6095be",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID X Y BLDFIE_WeigAver CECSOL_WeigAver CHELSA_bio18 CHELSA_bio4 convergence cti dev-magnitude eastness elev forestheight glad_ard_SVVI_max glad_ard_SVVI_med glad_ard_SVVI_min northness ORCDRC_WeigAver outlet_dist_dw_basin SBIO3_Isothermality_5_15cm SBIO4_Temperature_Seasonality_5_15cm treecover\r\n",
      "1 6.050001 49.727499 1540 13 2113 5893 -10.4865598678589 -238043120 1.15841722488403 0.0690935924649239 353.983123779297 23 276.87109375 46.444091796875 347.665405273438 0.0424997806549072 9 780403 19.7989921569824 440.672210693359 85 \r\n",
      "2 6.0500017 49.922155 1491 12 1993 5912 33.2743606567383 -208915344 -1.75534081459045 0.269112348556519 267.511688232422 19 -49.5263671875 19.552734375 -130.541748046875 0.182779803872108 16 772777 20.8894119262695 457.756195068359 85 \r\n"
     ]
    }
   ],
   "source": [
    "! head -3 tree_height/txt/eu_x_y_predictors_select.txt # what we would get"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679df0b2",
   "metadata": {},
   "source": [
    "using the latitude longitude of each point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37cdb1b9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.050001 49.727499\r\n",
      "6.0500017 49.922155\r\n",
      "6.0500021 48.602377\r\n",
      "6.0500089 48.151979\r\n",
      "6.0500102 49.58841\r\n",
      "6.0500143 48.608456\r\n",
      "6.0500165 48.571401\r\n",
      "6.0500189 49.921613\r\n",
      "6.0500201 48.822645\r\n",
      "6.0500238 49.847522\r\n"
     ]
    }
   ],
   "source": [
    "! head tree_height/txt/eu_x_y_select.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1458e928",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1267239 tree_height/txt/eu_x_y_select.txt\r\n"
     ]
    }
   ],
   "source": [
    "! wc -l tree_height/txt/eu_x_y_select.txt # quite a lots of coords!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a88a7e",
   "metadata": {},
   "source": [
    "and the predictors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3bef57cf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tree_height/geodata_raster/BLDFIE_WeigAver.tif\r\n",
      "tree_height/geodata_raster/CECSOL_WeigAver.tif\r\n",
      "tree_height/geodata_raster/CHELSA_bio18.tif\r\n",
      "tree_height/geodata_raster/CHELSA_bio4.tif\r\n",
      "tree_height/geodata_raster/convergence.tif\r\n",
      "tree_height/geodata_raster/cti.tif\r\n",
      "tree_height/geodata_raster/dev-magnitude.tif\r\n",
      "tree_height/geodata_raster/eastness.tif\r\n",
      "tree_height/geodata_raster/elev.tif\r\n",
      "tree_height/geodata_raster/forestheight.tif\r\n",
      "tree_height/geodata_raster/glad_ard_SVVI_max.tif\r\n",
      "tree_height/geodata_raster/glad_ard_SVVI_med.tif\r\n",
      "tree_height/geodata_raster/glad_ard_SVVI_min.tif\r\n",
      "tree_height/geodata_raster/latitude.tif\r\n",
      "tree_height/geodata_raster/longitude.tif\r\n",
      "tree_height/geodata_raster/northness.tif\r\n",
      "tree_height/geodata_raster/ORCDRC_WeigAver.tif\r\n",
      "tree_height/geodata_raster/outlet_dist_dw_basin.tif\r\n",
      "tree_height/geodata_raster/SBIO3_Isothermality_5_15cm.tif\r\n",
      "tree_height/geodata_raster/SBIO4_Temperature_Seasonality_5_15cm.tif\r\n",
      "tree_height/geodata_raster/treecover.tif\r\n"
     ]
    }
   ],
   "source": [
    "! ls tree_height/geodata_raster/*.tif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b7214b",
   "metadata": {},
   "source": [
    "## Running `rio` tool and using the `bash` shell and its tools\n",
    "### by Francesco Lovergine\n",
    "\n",
    "RasterIO has also a command line tool (`rio`) which can be used to perform a series of operation on rasters, which complementary in respect with the GDAL tools.If you install rasterio from distribution/kit it will reside in the ordinary system paths (note: you could find a `rasterio` binary instead of `rio`). If you install from the PyPI repository via `pip` it will install under `~/.local/bin`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5e82fd3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usage: rio [OPTIONS] COMMAND [ARGS]...\r\n",
      "\r\n",
      "  Rasterio command line interface.\r\n",
      "\r\n",
      "Options:\r\n",
      "  -v, --verbose           Increase verbosity.\r\n",
      "  -q, --quiet             Decrease verbosity.\r\n",
      "  --aws-profile TEXT      Select a profile from the AWS credentials file\r\n",
      "  --aws-no-sign-requests  Make requests anonymously\r\n",
      "  --aws-requester-pays    Requester pays data transfer costs\r\n",
      "  --version               Show the version and exit.\r\n",
      "  --gdal-version\r\n",
      "  --show-versions         Show dependency versions\r\n",
      "  --help                  Show this message and exit.\r\n",
      "\r\n",
      "Commands:\r\n",
      "  blocks     Write dataset blocks as GeoJSON features.\r\n",
      "  bounds     Write bounding boxes to stdout as GeoJSON.\r\n",
      "  calc       Raster data calculator.\r\n",
      "  clip       Clip a raster to given bounds.\r\n",
      "  convert    Copy and convert raster dataset.\r\n",
      "  edit-info  Edit dataset metadata.\r\n",
      "  env        Print information about the Rasterio environment.\r\n",
      "  gcps       Print ground control points as GeoJSON.\r\n",
      "  info       Print information about a data file.\r\n",
      "  insp       Open a data file and start an interpreter.\r\n",
      "  mask       Mask in raster using features.\r\n",
      "  merge      Merge a stack of raster datasets.\r\n",
      "  overview   Construct overviews in an existing dataset.\r\n",
      "  rasterize  Rasterize features.\r\n",
      "  rm         Delete a dataset.\r\n",
      "  sample     Sample a dataset.\r\n",
      "  shapes     Write shapes extracted from bands or masks.\r\n",
      "  stack      Stack a number of bands into a multiband dataset.\r\n",
      "  transform  Transform coordinates.\r\n",
      "  warp       Warp a raster dataset.\r\n"
     ]
    }
   ],
   "source": [
    "! rio --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6021fe1",
   "metadata": {},
   "source": [
    "The goal of the next few snippets of code is creating in Python and rasterio. That can be done either by using th `rio` tool or completely by Python script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d77549",
   "metadata": {},
   "source": [
    "First of all, the input for rio-sample submodule needs to be in list form, and that can be easily done via `sed` tool (or even `awk` if you prefer so):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8fd9ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.050001,49.727499]\r\n",
      "[6.0500017,49.922155]\r\n",
      "[6.0500021,48.602377]\r\n",
      "[6.0500089,48.151979]\r\n",
      "[6.0500102,49.58841]\r\n",
      "[6.0500143,48.608456]\r\n",
      "[6.0500165,48.571401]\r\n",
      "[6.0500189,49.921613]\r\n",
      "[6.0500201,48.822645]\r\n",
      "[6.0500238,49.847522]\r\n"
     ]
    }
   ],
   "source": [
    "! head tree_height/txt/eu_x_y_select.txt | sed -e 's/ /,/' -e 's/^/[/' -e 's/$/]/' # why and how?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c649dde4",
   "metadata": {},
   "source": [
    "Once created a compatible input data file for `rio`, it can be used to sample every georaster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "109888de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1540]\r\n",
      "[1491]\r\n",
      "[1521]\r\n",
      "[1526]\r\n",
      "[1547]\r\n",
      "[1515]\r\n",
      "[1520]\r\n",
      "[1490]\r\n",
      "[1554]\r\n",
      "[1521]\r\n"
     ]
    }
   ],
   "source": [
    "! head tree_height/txt/eu_x_y_select.txt | sed -e 's/ /,/' -e 's/^/[/' -e 's/$/]/' | rio sample tree_height/geodata_raster/BLDFIE_WeigAver.tif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "676052a0",
   "metadata": {},
   "source": [
    "Now, in principle you could stack together the input predictors and apply later the sampling. That could be done via `gdalbuildvrt` or `rio-stack`, BUT they both work currently only for homogeneous `dtype`, which is not our case, unfortunately.\n",
    "\n",
    "*Homework: extract data types and sizes from all those files and check rasters are different types with the same dimensions. Hint: you can do that via rio or gdal tools or pktools* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9da1fb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rio stack `ls tree_height/geodata_raster/*.tif|grep -Ev 'latitude|longitude'` -o /tmp/tree_height_preds.tif\n",
    "# gdalbuildvrt tree_height/geodata_raster/*.tif -o /tmp/predictors.vrt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a052e6",
   "metadata": {},
   "source": [
    "One quite simple way to get the final result is using `rio-sample` to sample separately each field, then using `paste` to join together each per-field file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f35ac50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "real\t20m51.133s\n",
      "user\t18m36.829s\n",
      "sys\t2m39.808s\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# this is VERY slow on 1M of records...\n",
    "time (\n",
    "FILES=$(awk '{if (NR==1) print $4,$5,$6,$7,$8,$9,$10,$11,$12,$13,$14,$15,$16,$17,$18,$19,$20,$21,$22}' tree_height/txt/eu_x_y_predictors_select.txt)\n",
    "for n in $FILES \n",
    "do \n",
    "    sed -e 's/ /,/' -e 's/^/[/' -e 's/$/]/' tree_height/txt/eu_x_y_select.txt | rio sample tree_height/geodata_raster/$n.tif | tr -d '[]' > /tmp/$n\n",
    "done\n",
    "\n",
    "seq $(wc -l tree_height/txt/eu_x_y_select.txt|cut -d' ' -f1) >/tmp/ids\n",
    "echo 'ID X Y' \"$FILES\" >  tree_height/txt/eu_x_y_predictors_select_rio.txt\n",
    "paste -d ' ' /tmp/ids tree_height/txt/eu_x_y_select.txt \\\n",
    "$(for n in  $(awk '{if (NR==1) print $4,$5,$6,$7,$8,$9,$10,$11,$12,$13,$14,$15,$16,$17,$18,$19,$20,$21,$22}' tree_height/txt/eu_x_y_predictors_select.txt); do ls /tmp/$n ; done) \\\n",
    ">> tree_height/txt/eu_x_y_predictors_select_rio.txt \n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfd3626",
   "metadata": {},
   "source": [
    "Running time\n",
    "\n",
    "    real\t20m51.133s\n",
    "    user\t18m36.829s\n",
    "    sys \t2m39.808s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8251788d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID X Y BLDFIE_WeigAver CECSOL_WeigAver CHELSA_bio18 CHELSA_bio4 convergence cti dev-magnitude eastness elev forestheight glad_ard_SVVI_max glad_ard_SVVI_med glad_ard_SVVI_min northness ORCDRC_WeigAver outlet_dist_dw_basin SBIO3_Isothermality_5_15cm SBIO4_Temperature_Seasonality_5_15cm treecover\r\n",
      "1 6.050001 49.727499 1540 13 2113 5893 -10.486559867858887 -238043120 1.1584172248840332 0.06909359246492386 353.9831237792969 23 276.87109375 46.444091796875 347.6654052734375 0.04249978065490723 9 780403 19.798992156982422 440.6722106933594 85\r\n",
      "2 6.0500017 49.922155 1491 12 1993 5912 33.27436065673828 -208915344 -1.755340814590454 0.26911234855651855 267.5116882324219 19 -49.5263671875 19.552734375 -130.541748046875 0.18277980387210846 16 772777 20.88941192626953 457.7561950683594 85\r\n"
     ]
    }
   ],
   "source": [
    "! head -3  tree_height/txt/eu_x_y_predictors_select_rio.txt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5adc96a3",
   "metadata": {},
   "source": [
    "## Running `gdallocationinfo` tool and using the `bash` shell and its tools\n",
    "### By Giuseppe Amatulli"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee3dad6e",
   "metadata": {},
   "source": [
    "We are going to use gdallocationinfo to extract information in each raster predictors. \n",
    "\n",
    "\n",
    "    Usage: gdallocationinfo [--help-general] [-xml] [-lifonly] [-valonly]\n",
    "                        [-b band]* [-overview overview_level]\n",
    "                        [-l_srs srs_def] [-geoloc] [-wgs84]\n",
    "                        [-oo NAME=VALUE]* srcfile x y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39886717",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "real\t1m50.404s\n",
      "user\t1m24.222s\n",
      "sys\t0m12.117s\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "time (\n",
    "for file in $(awk '{if (NR==1) print $1=\"\", $2=\"\", $3=\"\", $0}' tree_height/txt/eu_x_y_predictors_select.txt);  do \n",
    "echo $file > tree_height/txt/$file.txt\n",
    "gdallocationinfo -valonly -geoloc -wgs84 tree_height/geodata_raster/$file.tif < tree_height/txt/eu_x_y_select.txt >> tree_height/txt/$file.txt\n",
    "done \n",
    "\n",
    "paste -d \" \" <(awk '{ print $1,$2,$3}' tree_height/txt/eu_x_y_predictors_select.txt) \\\n",
    "$(for file in  $(awk '{if (NR==1)  print $1=\"\", $2=\"\", $3=\"\", $0}' tree_height/txt/eu_x_y_predictors_select.txt); do ls tree_height/txt/$file.txt; done) \\\n",
    "> tree_height/txt/eu_x_y_predictors_select_gdal.txt \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43381c94",
   "metadata": {},
   "source": [
    "Running time \n",
    "\n",
    "    real\t1m50.404s\n",
    "    user\t1m24.222s\n",
    "    sys \t0m12.117s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7bc52c5a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID X Y BLDFIE_WeigAver CECSOL_WeigAver CHELSA_bio18 CHELSA_bio4 convergence cti dev-magnitude eastness elev forestheight glad_ard_SVVI_max glad_ard_SVVI_med glad_ard_SVVI_min northness ORCDRC_WeigAver outlet_dist_dw_basin SBIO3_Isothermality_5_15cm SBIO4_Temperature_Seasonality_5_15cm treecover\r\n",
      "1 6.050001 49.727499 1540 13 2113 5893 -10.4865598678589 -238043120 1.15841722488403 0.0690935924649239 353.983123779297 23 276.87109375 46.444091796875 347.665405273438 0.0424997806549072 9 780403 19.7989921569824 440.672210693359 85\r\n",
      "2 6.0500017 49.922155 1491 12 1993 5912 33.2743606567383 -208915344 -1.75534081459045 0.269112348556519 267.511688232422 19 -49.5263671875 19.552734375 -130.541748046875 0.182779803872108 16 772777 20.8894119262695 457.756195068359 85\r\n"
     ]
    }
   ],
   "source": [
    "! head -3 tree_height/txt/eu_x_y_predictors_select_gdal.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f65666",
   "metadata": {},
   "source": [
    "Of course, the same result can be achieved with direct read/write via rasterio packagein one full Python script. \n",
    "\n",
    "## Using Python with rasterio\n",
    "### Script construction, step by step. By Francesco Lovergine\n",
    "\n",
    "Due to the size of the dataset it is mandatory increasing the memory available for the VM and possibly add on demand swap space (i.e. virtual memory on disk), for instance via:\n",
    "\n",
    "    sudo apt install swapspace\n",
    "    \n",
    "Of course, consider that eventually it could require a lot of temporary storage taken under `/var/lib/swapspace` which could be freed after use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "884c12e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import glob\n",
    "import rasterio\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "27461af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = []\n",
    "for filename in glob.glob('tree_height/geodata_raster/[!l]*.tif'):\n",
    "    ds = rasterio.open(filename, mode='r')\n",
    "    files.append(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0abf7f3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<open DatasetReader name='tree_height/geodata_raster/BLDFIE_WeigAver.tif' mode='r'>,\n",
       " <open DatasetReader name='tree_height/geodata_raster/CECSOL_WeigAver.tif' mode='r'>,\n",
       " <open DatasetReader name='tree_height/geodata_raster/CHELSA_bio18.tif' mode='r'>,\n",
       " <open DatasetReader name='tree_height/geodata_raster/CHELSA_bio4.tif' mode='r'>,\n",
       " <open DatasetReader name='tree_height/geodata_raster/ORCDRC_WeigAver.tif' mode='r'>,\n",
       " <open DatasetReader name='tree_height/geodata_raster/SBIO3_Isothermality_5_15cm.tif' mode='r'>,\n",
       " <open DatasetReader name='tree_height/geodata_raster/SBIO4_Temperature_Seasonality_5_15cm.tif' mode='r'>,\n",
       " <open DatasetReader name='tree_height/geodata_raster/convergence.tif' mode='r'>,\n",
       " <open DatasetReader name='tree_height/geodata_raster/cti.tif' mode='r'>,\n",
       " <open DatasetReader name='tree_height/geodata_raster/dev-magnitude.tif' mode='r'>,\n",
       " <open DatasetReader name='tree_height/geodata_raster/eastness.tif' mode='r'>,\n",
       " <open DatasetReader name='tree_height/geodata_raster/elev.tif' mode='r'>,\n",
       " <open DatasetReader name='tree_height/geodata_raster/forestheight.tif' mode='r'>,\n",
       " <open DatasetReader name='tree_height/geodata_raster/glad_ard_SVVI_max.tif' mode='r'>,\n",
       " <open DatasetReader name='tree_height/geodata_raster/glad_ard_SVVI_med.tif' mode='r'>,\n",
       " <open DatasetReader name='tree_height/geodata_raster/glad_ard_SVVI_min.tif' mode='r'>,\n",
       " <open DatasetReader name='tree_height/geodata_raster/northness.tif' mode='r'>,\n",
       " <open DatasetReader name='tree_height/geodata_raster/outlet_dist_dw_basin.tif' mode='r'>,\n",
       " <open DatasetReader name='tree_height/geodata_raster/treecover.tif' mode='r'>]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fc98e34f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19\n"
     ]
    }
   ],
   "source": [
    "print(len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "063a1650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BLDFIE_WeigAver.tif'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.basename(files[0].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e8782711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BLDFIE_WeigAver'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(name, ext) = os.path.splitext(os.path.basename(files[0].name))\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8788fe91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BLDFIE_WeigAver CECSOL_WeigAver CHELSA_bio18 CHELSA_bio4 ORCDRC_WeigAver SBIO3_Isothermality_5_15cm SBIO4_Temperature_Seasonality_5_15cm convergence cti dev-magnitude eastness elev forestheight glad_ard_SVVI_max glad_ard_SVVI_med glad_ard_SVVI_min northness outlet_dist_dw_basin treecover'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header = ''\n",
    "for ds in files:\n",
    "    field_name =   os.path.splitext(os.path.basename(ds.name))[0]\n",
    "    header += ' '+field_name\n",
    "header.lstrip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b490ef",
   "metadata": {},
   "source": [
    "Starting from those files now open in rasterio, it is possible to read the band and store them in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eaadf21a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1523,  1523, 65535, ..., 65535, 65535, 65535],\n",
       "       [65535, 65535, 65535, ..., 65535, 65535, 65535],\n",
       "       [65535, 65535, 65535, ..., 65535, 65535, 65535],\n",
       "       ...,\n",
       "       [ 1514,  1514,  1514, ...,  1455,  1455,  1455],\n",
       "       [65535, 65535, 65535, ...,  1457,  1457,  1457],\n",
       "       [65535, 65535, 65535, ...,  1458,  1458,  1458]], dtype=uint16)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "band = files[0].read(1)\n",
    "band"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a1cb10d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = []\n",
    "for ds in files:\n",
    "    bands.append(ds.read(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "89adf398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 1523,  1523, 65535, ..., 65535, 65535, 65535],\n",
       "        [65535, 65535, 65535, ..., 65535, 65535, 65535],\n",
       "        [65535, 65535, 65535, ..., 65535, 65535, 65535],\n",
       "        ...,\n",
       "        [ 1514,  1514,  1514, ...,  1455,  1455,  1455],\n",
       "        [65535, 65535, 65535, ...,  1457,  1457,  1457],\n",
       "        [65535, 65535, 65535, ...,  1458,  1458,  1458]], dtype=uint16),\n",
       " array([[   11,    11, 65535, ..., 65535, 65535, 65535],\n",
       "        [65535, 65535, 65535, ..., 65535, 65535, 65535],\n",
       "        [65535, 65535, 65535, ..., 65535, 65535, 65535],\n",
       "        ...,\n",
       "        [   16,    16,    16, ...,    20,    20,    20],\n",
       "        [65535, 65535, 65535, ...,    19,    19,    19],\n",
       "        [65535, 65535, 65535, ...,    19,    19,    19]], dtype=uint16),\n",
       " array([[ 2024,  2024, 65535, ..., 65535, 65535, 65535],\n",
       "        [65535, 65535, 65535, ..., 65535, 65535, 65535],\n",
       "        [65535, 65535, 65535, ..., 65535, 65535, 65535],\n",
       "        ...,\n",
       "        [ 2401,  2401,  2401, ...,  4405,  4405,  4405],\n",
       "        [65535, 65535, 65535, ...,  4406,  4406,  4406],\n",
       "        [65535, 65535, 65535, ...,  4408,  4408,  4408]], dtype=uint16),\n",
       " array([[ 5879,  5879, 65535, ..., 65535, 65535, 65535],\n",
       "        [65535, 65535, 65535, ..., 65535, 65535, 65535],\n",
       "        [65535, 65535, 65535, ..., 65535, 65535, 65535],\n",
       "        ...,\n",
       "        [ 6272,  6272,  6272, ...,  6348,  6348,  6348],\n",
       "        [65535, 65535, 65535, ...,  6348,  6348,  6348],\n",
       "        [65535, 65535, 65535, ...,  6349,  6349,  6349]], dtype=uint16),\n",
       " array([[   12,    12, 65535, ..., 65535, 65535, 65535],\n",
       "        [65535, 65535, 65535, ..., 65535, 65535, 65535],\n",
       "        [65535, 65535, 65535, ..., 65535, 65535, 65535],\n",
       "        ...,\n",
       "        [    9,     9,     9, ...,    23,    23,    23],\n",
       "        [65535, 65535, 65535, ...,    22,    22,    22],\n",
       "        [65535, 65535, 65535, ...,    21,    21,    21]], dtype=uint16),\n",
       " array([[   22.9   ,    22.9   , -9999.    , ..., -9999.    , -9999.    ,\n",
       "         -9999.    ],\n",
       "        [-9999.    , -9999.    , -9999.    , ..., -9999.    , -9999.    ,\n",
       "         -9999.    ],\n",
       "        [-9999.    , -9999.    , -9999.    , ..., -9999.    , -9999.    ,\n",
       "         -9999.    ],\n",
       "        ...,\n",
       "        [   21.3825,    21.3825,    21.3825, ...,    24.24  ,    24.24  ,\n",
       "            24.24  ],\n",
       "        [-9999.    , -9999.    , -9999.    , ...,    24.264 ,    24.264 ,\n",
       "            24.264 ],\n",
       "        [-9999.    , -9999.    , -9999.    , ...,    24.288 ,    24.288 ,\n",
       "            24.288 ]], dtype=float32),\n",
       " array([[  470.5   ,   470.5   , -9999.    , ..., -9999.    , -9999.    ,\n",
       "         -9999.    ],\n",
       "        [-9999.    , -9999.    , -9999.    , ..., -9999.    , -9999.    ,\n",
       "         -9999.    ],\n",
       "        [-9999.    , -9999.    , -9999.    , ..., -9999.    , -9999.    ,\n",
       "         -9999.    ],\n",
       "        ...,\n",
       "        [  514.73  ,   514.73  ,   514.73  , ...,   491.1825,   491.1825,\n",
       "           491.1825],\n",
       "        [-9999.    , -9999.    , -9999.    , ...,   491.0895,   491.0895,\n",
       "           491.0895],\n",
       "        [-9999.    , -9999.    , -9999.    , ...,   490.9965,   490.9965,\n",
       "           490.9965]], dtype=float32),\n",
       " array([[-3.0291458e+01, -3.0291458e+01, -9.9990000e+03, ...,\n",
       "         -9.9990000e+03, -9.9990000e+03, -9.9990000e+03],\n",
       "        [-9.9990000e+03, -9.9990000e+03, -9.9990000e+03, ...,\n",
       "         -9.9990000e+03, -9.9990000e+03, -9.9990000e+03],\n",
       "        [-9.9990000e+03, -9.9990000e+03, -9.9990000e+03, ...,\n",
       "         -9.9990000e+03, -9.9990000e+03, -9.9990000e+03],\n",
       "        ...,\n",
       "        [-5.1806598e+00, -5.1806598e+00, -5.7902360e+00, ...,\n",
       "          4.0210270e+01,  4.8858276e+01,  4.8858276e+01],\n",
       "        [-9.9990000e+03, -9.9990000e+03, -9.9990000e+03, ...,\n",
       "          4.1173668e+01,  5.1179237e+01,  5.1179237e+01],\n",
       "        [-9.9990000e+03, -9.9990000e+03, -9.9990000e+03, ...,\n",
       "          3.4467628e+01,  4.4355145e+01,  4.4355145e+01]], dtype=float32),\n",
       " array([[ -266332416,  -266332416, -2147483648, ..., -2147483648,\n",
       "         -2147483648, -2147483648],\n",
       "        [-2147483648, -2147483648, -2147483648, ..., -2147483648,\n",
       "         -2147483648, -2147483648],\n",
       "        [-2147483648, -2147483648, -2147483648, ..., -2147483648,\n",
       "         -2147483648, -2147483648],\n",
       "        ...,\n",
       "        [ -330251232,  -330251232,  -330806208, ...,   -72420176,\n",
       "           -38702784,   -38702784],\n",
       "        [-2147483648, -2147483648, -2147483648, ...,   -97209304,\n",
       "           -71794584,   -71794584],\n",
       "        [-2147483648, -2147483648, -2147483648, ...,  -112299568,\n",
       "           -99132240,   -99132240]], dtype=int32),\n",
       " array([[ 6.7067027e-01,  6.7067027e-01, -9.9990000e+03, ...,\n",
       "         -9.9990000e+03, -9.9990000e+03, -9.9990000e+03],\n",
       "        [-9.9990000e+03, -9.9990000e+03, -9.9990000e+03, ...,\n",
       "         -9.9990000e+03, -9.9990000e+03, -9.9990000e+03],\n",
       "        [-9.9990000e+03, -9.9990000e+03, -9.9990000e+03, ...,\n",
       "         -9.9990000e+03, -9.9990000e+03, -9.9990000e+03],\n",
       "        ...,\n",
       "        [ 5.0633794e-01,  5.0633794e-01,  5.0400752e-01, ...,\n",
       "          1.6250600e+00,  1.6136067e+00,  1.6136067e+00],\n",
       "        [-9.9990000e+03, -9.9990000e+03, -9.9990000e+03, ...,\n",
       "          1.6310033e+00,  1.6191456e+00,  1.6191456e+00],\n",
       "        [-9.9990000e+03, -9.9990000e+03, -9.9990000e+03, ...,\n",
       "          1.6421642e+00,  1.6330340e+00,  1.6330340e+00]], dtype=float32),\n",
       " array([[-6.9691122e-02, -6.9691122e-02, -9.9990000e+03, ...,\n",
       "         -9.9990000e+03, -9.9990000e+03, -9.9990000e+03],\n",
       "        [-9.9990000e+03, -9.9990000e+03, -9.9990000e+03, ...,\n",
       "         -9.9990000e+03, -9.9990000e+03, -9.9990000e+03],\n",
       "        [-9.9990000e+03, -9.9990000e+03, -9.9990000e+03, ...,\n",
       "         -9.9990000e+03, -9.9990000e+03, -9.9990000e+03],\n",
       "        ...,\n",
       "        [-1.5847646e-02, -1.5847646e-02, -7.8007574e-03, ...,\n",
       "          1.3672341e-02,  1.2951906e-02,  1.2951906e-02],\n",
       "        [-9.9990000e+03, -9.9990000e+03, -9.9990000e+03, ...,\n",
       "          1.4678583e-02,  1.4141800e-02,  1.4141800e-02],\n",
       "        [-9.9990000e+03, -9.9990000e+03, -9.9990000e+03, ...,\n",
       "          1.3527840e-02,  1.3261721e-02,  1.3261721e-02]], dtype=float32),\n",
       " array([[  379.93466,   379.93466, -9999.     , ..., -9999.     ,\n",
       "         -9999.     , -9999.     ],\n",
       "        [-9999.     , -9999.     , -9999.     , ..., -9999.     ,\n",
       "         -9999.     , -9999.     ],\n",
       "        [-9999.     , -9999.     , -9999.     , ..., -9999.     ,\n",
       "         -9999.     , -9999.     ],\n",
       "        ...,\n",
       "        [  259.5505 ,   259.5505 ,   260.30533, ...,   737.22675,\n",
       "           736.4584 ,   736.4584 ],\n",
       "        [-9999.     , -9999.     , -9999.     , ...,   737.5121 ,\n",
       "           736.75574,   736.75574],\n",
       "        [-9999.     , -9999.     , -9999.     , ...,   738.052  ,\n",
       "           737.48334,   737.48334]], dtype=float32),\n",
       " array([[  0,   0, 255, ..., 255, 255, 255],\n",
       "        [255, 255, 255, ..., 255, 255, 255],\n",
       "        [255, 255, 255, ..., 255, 255, 255],\n",
       "        ...,\n",
       "        [  4,   4,   3, ...,  27,  29,  29],\n",
       "        [255, 255, 255, ...,  24,  25,  28],\n",
       "        [255, 255, 255, ...,  22,  26,  27]], dtype=uint8),\n",
       " array([[ 1492.6785  ,  1306.2141  , -9999.      , ..., -9999.      ,\n",
       "         -9999.      , -9999.      ],\n",
       "        [-9999.      , -9999.      , -9999.      , ..., -9999.      ,\n",
       "         -9999.      , -9999.      ],\n",
       "        [-9999.      , -9999.      , -9999.      , ..., -9999.      ,\n",
       "         -9999.      , -9999.      ],\n",
       "        ...,\n",
       "        [  406.16797 ,   512.14136 ,   852.699   , ...,    13.673584,\n",
       "            16.567871,  -119.38574 ],\n",
       "        [-9999.      , -9999.      , -9999.      , ...,    53.41284 ,\n",
       "           106.63818 ,  -103.65137 ],\n",
       "        [-9999.      , -9999.      , -9999.      , ...,  -225.1709  ,\n",
       "            59.3938  ,   -91.39722 ]], dtype=float32),\n",
       " array([[ 1085.7559  ,  1035.9121  , -9999.      , ..., -9999.      ,\n",
       "         -9999.      , -9999.      ],\n",
       "        [-9999.      , -9999.      , -9999.      , ..., -9999.      ,\n",
       "         -9999.      , -9999.      ],\n",
       "        [-9999.      , -9999.      , -9999.      , ..., -9999.      ,\n",
       "         -9999.      , -9999.      ],\n",
       "        ...,\n",
       "        [  370.3777  ,   485.29468 ,   596.9763  , ...,  -115.798096,\n",
       "           -88.07202 ,   -88.33276 ],\n",
       "        [-9999.      , -9999.      , -9999.      , ...,   -47.25415 ,\n",
       "           -46.921387,  -104.95679 ],\n",
       "        [-9999.      , -9999.      , -9999.      , ...,  -243.46167 ,\n",
       "           -13.637451,  -121.86597 ]], dtype=float32),\n",
       " array([[  959.5752  ,   688.7239  , -9999.      , ..., -9999.      ,\n",
       "         -9999.      , -9999.      ],\n",
       "        [-9999.      , -9999.      , -9999.      , ..., -9999.      ,\n",
       "         -9999.      , -9999.      ],\n",
       "        [-9999.      , -9999.      , -9999.      , ..., -9999.      ,\n",
       "         -9999.      , -9999.      ],\n",
       "        ...,\n",
       "        [  311.42188 ,   464.50146 ,   542.05835 , ...,  -282.40723 ,\n",
       "          -237.9851  ,  -215.59985 ],\n",
       "        [-9999.      , -9999.      , -9999.      , ...,  -162.25928 ,\n",
       "          -190.5232  ,  -179.57202 ],\n",
       "        [-9999.      , -9999.      , -9999.      , ...,  -221.65869 ,\n",
       "           -44.732178,  -285.79663 ]], dtype=float32),\n",
       " array([[-7.71632195e-02, -7.71632195e-02, -9.99900000e+03, ...,\n",
       "         -9.99900000e+03, -9.99900000e+03, -9.99900000e+03],\n",
       "        [-9.99900000e+03, -9.99900000e+03, -9.99900000e+03, ...,\n",
       "         -9.99900000e+03, -9.99900000e+03, -9.99900000e+03],\n",
       "        [-9.99900000e+03, -9.99900000e+03, -9.99900000e+03, ...,\n",
       "         -9.99900000e+03, -9.99900000e+03, -9.99900000e+03],\n",
       "        ...,\n",
       "        [ 1.26748577e-01,  1.26748577e-01,  1.23799555e-01, ...,\n",
       "          5.50076319e-03,  5.47871692e-03,  5.47871692e-03],\n",
       "        [-9.99900000e+03, -9.99900000e+03, -9.99900000e+03, ...,\n",
       "          6.67779474e-03,  6.95462432e-03,  6.95462432e-03],\n",
       "        [-9.99900000e+03, -9.99900000e+03, -9.99900000e+03, ...,\n",
       "          6.94931159e-03,  7.58498861e-03,  7.58498861e-03]], dtype=float32),\n",
       " array([[ 790129,  790129,   -9999, ...,   -9999,   -9999,   -9999],\n",
       "        [  -9999,   -9999,   -9999, ...,   -9999,   -9999,   -9999],\n",
       "        [  -9999,   -9999,   -9999, ...,   -9999,   -9999,   -9999],\n",
       "        ...,\n",
       "        [ 769627,  769627,  769634, ..., 2915172, 2915151, 2915151],\n",
       "        [  -9999,   -9999,   -9999, ..., 2915209, 2915168, 2915168],\n",
       "        [  -9999,   -9999,   -9999, ..., 2915389, 2915195, 2915195]],\n",
       "       dtype=int32),\n",
       " array([[ 37,  37, 255, ..., 255, 255, 255],\n",
       "        [255, 255, 255, ..., 255, 255, 255],\n",
       "        [255, 255, 255, ..., 255, 255, 255],\n",
       "        ...,\n",
       "        [ 29,  27,  27, ...,  95,  87,  94],\n",
       "        [255, 255, 255, ...,  98,  92,  85],\n",
       "        [255, 255, 255, ...,  72,  72,  85]], dtype=uint8)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae8ca21",
   "metadata": {},
   "source": [
    "Now let's have a trial for concatenating raster values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fba201f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 6.050001 49.727499 1540 13 2113 5893 9 19.798992156982422 440.6722106933594 -10.486559867858887 -238043120 1.1584172248840332 0.06909359246492386 353.9831237792969 23 276.87109375 46.444091796875 347.6654052734375 0.04249978065490723 780403 85 \n",
      "2 6.0500017 49.922155 1491 12 1993 5912 16 20.88941192626953 457.7561950683594 33.27436065673828 -208915344 -1.755340814590454 0.26911234855651855 267.5116882324219 19 -49.5263671875 19.552734375 -130.541748046875 0.18277980387210846 772777 85 \n",
      "3 6.0500021 48.602377 1521 17 2124 5983 14 20.695877075195312 481.87969970703125 0.045293472707271576 -137479792 1.9087798595428467 -0.01605454459786415 389.75115966796875 21 93.25732421875 50.74365234375 384.5224609375 0.0362534299492836 898820 62 \n",
      "4 6.0500089 48.151979 1526 16 2569 6130 15 19.375 479.4102783203125 -33.654273986816406 -267223072 0.9657867550849915 0.06776714324951172 380.20770263671875 27 542.4013671875 202.26416015625 386.15673828125 0.0051393029280006886 831824 85 \n",
      "5 6.0500102 49.58841 1547 14 2108 5923 17 18.77750015258789 457.88006591796875 27.493824005126953 -107809368 -0.1626242697238922 0.014064788818359375 308.04278564453125 25 136.04833984375 146.835205078125 198.12744140625 0.02884702757000923 796962 85 \n",
      "6 6.0500143 48.608456 1515 19 2124 6010 14 19.398880004882812 474.3313293457031 -1.6020394563674927 17384282 1.44797945022583 -0.01891239918768406 364.527099609375 18 221.33984375 247.38720703125 480.387939453125 0.042747415602207184 897945 62 \n",
      "7 6.0500165 48.571401 1520 19 2169 6147 11 20.17045021057129 476.4145202636719 27.856502532958984 -66516432 -1.0739555358886719 0.0022801030427217484 254.67959594726562 19 125.25048828125 87.865234375 160.69677734375 0.037254270166158676 908426 96 \n",
      "8 6.0500189 49.921613 1490 12 1995 5912 15 20.8559627532959 457.1954040527344 22.10213851928711 -297770784 -1.402632713317871 0.30976489186286926 294.9277648925781 26 -86.7294921875 -145.584228515625 -190.06298828125 0.22243468463420868 772784 86 \n",
      "9 6.0500201 48.822645 1554 18 1973 6138 8 21.81229019165039 496.2311096191406 18.496583938598633 -25336536 -0.8000159859657288 0.0103699816390872 240.49375915527344 22 -51.470703125 -245.88671875 172.07470703125 0.004428229294717312 839132 64 \n",
      "10 6.0500238 49.847522 1521 15 2187 5886 13 21.137710571289062 466.9766845703125 -5.660452842712402 -278652608 1.4779508113861084 -0.06871972978115082 376.671142578125 12 277.29736328125 273.141845703125 -138.89599609375 0.09881718456745148 768873 70 \n"
     ]
    }
   ],
   "source": [
    "with open('tree_height/txt/eu_x_y_select.txt') as csvfile:\n",
    "    coords = csv.reader(csvfile, delimiter=' ')\n",
    "    i = 1\n",
    "    for (long, lat) in coords:\n",
    "        print('{} {} {} '.format(i, long, lat),end='')\n",
    "        for j, ds in enumerate(files):\n",
    "            idx = ds.index(float(long), float(lat))\n",
    "            band = bands[j]\n",
    "            val = band[idx]\n",
    "            print('{} '.format(val), end='')\n",
    "        print(\"\")b\n",
    "        i+=1\n",
    "        if i > 10: break # just for the very first rows and check\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4a717b",
   "metadata": {},
   "source": [
    "The first 10 rows seem correct in respect with the previous file, now it is only need to dump the rows to a file, with an appropriate header."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "cab790fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2min 10s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -r 1 -n 1\n",
    "with open('tree_height/txt/eu_x_y_predictors_select_new.txt', 'w') as out:\n",
    "    print('ID X Y' + header, file=out)\n",
    "    with open('tree_height/txt/eu_x_y_select.txt') as csvfile:\n",
    "        coords = csv.reader(csvfile, delimiter=' ')\n",
    "        i = 1\n",
    "        for (long, lat) in coords:\n",
    "            print('{} {} {} '.format(i, long, lat),end='', file=out)\n",
    "            for j, ds in enumerate(files):\n",
    "                idx = ds.index(float(long), float(lat))\n",
    "                band = bands[j]\n",
    "                val = band[idx]\n",
    "                print('{} '.format(val), end='', file=out)\n",
    "            print(\"\", file=out)\n",
    "            i+=1\n",
    "            if i>100000: break # that's to get a fast partial result..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0326ef0f",
   "metadata": {},
   "source": [
    "You can notice that the output is extremely slow. Efficiency can be eventually increased by changing the buffering size from the default one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f5f2bf41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID X Y BLDFIE_WeigAver CECSOL_WeigAver CHELSA_bio18 CHELSA_bio4 ORCDRC_WeigAver SBIO3_Isothermality_5_15cm SBIO4_Temperature_Seasonality_5_15cm convergence cti dev-magnitude eastness elev forestheight glad_ard_SVVI_max glad_ard_SVVI_med glad_ard_SVVI_min northness outlet_dist_dw_basin treecover\r\n",
      "1 6.050001 49.727499 1540 13 2113 5893 9 19.798992156982422 440.6722106933594 -10.486559867858887 -238043120 1.1584172248840332 0.06909359246492386 353.9831237792969 23 276.87109375 46.444091796875 347.6654052734375 0.04249978065490723 780403 85 \r\n",
      "2 6.0500017 49.922155 1491 12 1993 5912 16 20.88941192626953 457.7561950683594 33.27436065673828 -208915344 -1.755340814590454 0.26911234855651855 267.5116882324219 19 -49.5263671875 19.552734375 -130.541748046875 0.18277980387210846 772777 85 \r\n"
     ]
    }
   ],
   "source": [
    "! head -3 tree_height/txt/eu_x_y_predictors_select_new.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3264725c",
   "metadata": {},
   "source": [
    "### Stend-alone Python script. By Francesco Lovergine\n",
    "\n",
    "Running the script for the whole content of 1.2M of records take quite a full time, you can run it yourself or use the resulting file stored in the staging area of the VM and clone via git."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0912afe",
   "metadata": {},
   "source": [
    "    #!/usr/bin/env python3\n",
    "    #\n",
    "    # This is the whole script written in a proper way to work even in bash.\n",
    "    # You can copy&paste this block in a text `whatever.py` file, then\n",
    "    # chmod a+x whatever.py \n",
    "    # and run it as ./whatever.py\n",
    "    #\n",
    "    \n",
    "    import csv\n",
    "    import glob\n",
    "    import rasterio\n",
    "    import os.path\n",
    "\n",
    "    files = []\n",
    "    for filename in glob.glob('tree_height/geodata_raster/[!l]*.tif'):\n",
    "        ds = rasterio.open(filename, mode='r')\n",
    "        files.append(ds)\n",
    "\n",
    "    (name, ext) = os.path.splitext(os.path.basename(files[0].name))\n",
    "    header = ''\n",
    "    for ds in files:\n",
    "        field_name = os.path.splitext(os.path.basename(ds.name))[0]\n",
    "        header += ' '+field_name\n",
    "\n",
    "    print('Reading raster files...')\n",
    "\n",
    "    bands = []\n",
    "    for ds in files:\n",
    "        bands.append(ds.read(1))\n",
    "\n",
    "    print('Writing samples')\n",
    "\n",
    "    with open('tree_height/txt/eu_x_y_predictors_select_new.txt', 'w') as out:\n",
    "        print('ID X Y' + header, file=out)\n",
    "        with open('tree_height/txt/eu_x_y_select.txt') as csvfile:\n",
    "            coords = csv.reader(csvfile, delimiter=' ')\n",
    "            i = 1\n",
    "            for (long, lat) in coords:\n",
    "                print('{} {} {} '.format(i, long, lat),end='', file=out)\n",
    "                for j, ds in enumerate(files):\n",
    "                    idx = ds.index(float(long), float(lat))\n",
    "                    band = bands[j]\n",
    "                    val = band[idx]\n",
    "                    print('{} '.format(val), end='', file=out)\n",
    "                print(\"\", file=out)\n",
    "                if not i % 10: print('Record {} ...'.format(i))\n",
    "                i+=1\n",
    "        csvfile.close()\n",
    "    out.close()\n",
    "\n",
    "    print('Finished')\n",
    "\n",
    "    exit(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92738e5d",
   "metadata": {},
   "source": [
    "This script can be run by "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a308370",
   "metadata": {},
   "outputs": [],
   "source": [
    "! time python3 /media/sf_LVM_shared/my_SE_data/exercise/Tree_Height_02Predictors_extraction_python1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc54a5a9",
   "metadata": {},
   "source": [
    "## Using Python with rasterio and numpy\n",
    "### Script construction, step by step. By Hannah Weiser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4c6996",
   "metadata": {},
   "source": [
    "Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c643136",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import rasterio as rio\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e283c508",
   "metadata": {},
   "source": [
    "Create a list of (opened) raster datasets and of the corresponding field names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c5de16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = []\n",
    "fieldnames = []\n",
    "for filename in Path('tree_height/geodata_raster/').glob('[!l]*.tif'):\n",
    "    ds = rio.open(filename, mode='r')\n",
    "    datasets.append(ds)\n",
    "    fieldnames.append(filename.stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e4cd87e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['northness',\n",
       " 'forestheight',\n",
       " 'elev',\n",
       " 'CHELSA_bio4',\n",
       " 'SBIO3_Isothermality_5_15cm',\n",
       " 'SBIO4_Temperature_Seasonality_5_15cm',\n",
       " 'dev-magnitude',\n",
       " 'BLDFIE_WeigAver',\n",
       " 'CHELSA_bio18',\n",
       " 'glad_ard_SVVI_min',\n",
       " 'eastness',\n",
       " 'ORCDRC_WeigAver',\n",
       " 'cti',\n",
       " 'treecover',\n",
       " 'outlet_dist_dw_basin',\n",
       " 'glad_ard_SVVI_med',\n",
       " 'convergence',\n",
       " 'glad_ard_SVVI_max',\n",
       " 'CECSOL_WeigAver']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fieldnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "51f7d494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<open DatasetReader name='tree_height/geodata_raster/northness.tif' mode='r'>,\n",
       " <open DatasetReader name='tree_height/geodata_raster/forestheight.tif' mode='r'>,\n",
       " <open DatasetReader name='tree_height/geodata_raster/elev.tif' mode='r'>,\n",
       " <open DatasetReader name='tree_height/geodata_raster/CHELSA_bio4.tif' mode='r'>,\n",
       " <open DatasetReader name='tree_height/geodata_raster/SBIO3_Isothermality_5_15cm.tif' mode='r'>,\n",
       " <open DatasetReader name='tree_height/geodata_raster/SBIO4_Temperature_Seasonality_5_15cm.tif' mode='r'>,\n",
       " <open DatasetReader name='tree_height/geodata_raster/dev-magnitude.tif' mode='r'>,\n",
       " <open DatasetReader name='tree_height/geodata_raster/BLDFIE_WeigAver.tif' mode='r'>,\n",
       " <open DatasetReader name='tree_height/geodata_raster/CHELSA_bio18.tif' mode='r'>,\n",
       " <open DatasetReader name='tree_height/geodata_raster/glad_ard_SVVI_min.tif' mode='r'>,\n",
       " <open DatasetReader name='tree_height/geodata_raster/eastness.tif' mode='r'>,\n",
       " <open DatasetReader name='tree_height/geodata_raster/ORCDRC_WeigAver.tif' mode='r'>,\n",
       " <open DatasetReader name='tree_height/geodata_raster/cti.tif' mode='r'>,\n",
       " <open DatasetReader name='tree_height/geodata_raster/treecover.tif' mode='r'>,\n",
       " <open DatasetReader name='tree_height/geodata_raster/outlet_dist_dw_basin.tif' mode='r'>,\n",
       " <open DatasetReader name='tree_height/geodata_raster/glad_ard_SVVI_med.tif' mode='r'>,\n",
       " <open DatasetReader name='tree_height/geodata_raster/convergence.tif' mode='r'>,\n",
       " <open DatasetReader name='tree_height/geodata_raster/glad_ard_SVVI_max.tif' mode='r'>,\n",
       " <open DatasetReader name='tree_height/geodata_raster/CECSOL_WeigAver.tif' mode='r'>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be243180",
   "metadata": {},
   "source": [
    "Read the coordinates to a numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cc76b537",
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = np.genfromtxt('tree_height/txt/eu_x_y_select.txt', delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5ea2f72e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.050001 , 49.727499 ],\n",
       "       [ 6.0500017, 49.922155 ],\n",
       "       [ 6.0500021, 48.602377 ],\n",
       "       ...,\n",
       "       [ 9.9499985, 49.227932 ],\n",
       "       [ 9.9499988, 49.936763 ],\n",
       "       [ 9.9499996, 49.48964  ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8a395775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1267239, 2)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a90b061",
   "metadata": {},
   "source": [
    "Create a dictionary with an array of pixel values at the coordinates for each field (i.e. values sampled from each raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "869cb2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_val_dict = {}\n",
    "for i, ds in enumerate(datasets):\n",
    "    # transform coordinates to raster row and column indices\n",
    "    rows, cols = rio.transform.rowcol(ds.transform, coords[:, 0], coords[:, 1])\n",
    "    rowcols = np.array(list(zip(rows, cols)))\n",
    "    # read band of raster\n",
    "    band = ds.read(1)\n",
    "    # get values by indexing band with row and column indices\n",
    "    vals = np.array([band[row, col] for row, col in rowcols])\n",
    "    # add value array to dictionary\n",
    "    raster_val_dict[fieldnames[i]] = vals\n",
    "    ds.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60d18e5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'northness': array([ 0.04249978,  0.1827798 ,  0.03625343, ..., -0.06422238,\n",
       "        -0.00754081,  0.10954276], dtype=float32),\n",
       " 'forestheight': array([23, 19, 21, ..., 23, 27, 23], dtype=uint8),\n",
       " 'elev': array([353.98312, 267.5117 , 389.75116, ..., 422.33276, 306.65903,\n",
       "        349.73883], dtype=float32),\n",
       " 'CHELSA_bio4': array([5893, 5912, 5983, ..., 6622, 6495, 6588], dtype=uint16),\n",
       " 'SBIO3_Isothermality_5_15cm': array([19.798992, 20.889412, 20.695877, ..., 18.91893 , 17.010637,\n",
       "        17.769867], dtype=float32),\n",
       " 'SBIO4_Temperature_Seasonality_5_15cm': array([440.6722 , 457.7562 , 481.8797 , ..., 490.463  , 457.73627,\n",
       "        489.45746], dtype=float32),\n",
       " 'dev-magnitude': array([ 1.1584172 , -1.7553408 ,  1.9087799 , ...,  0.28438434,\n",
       "        -1.0900238 ,  0.52376586], dtype=float32),\n",
       " 'BLDFIE_WeigAver': array([1540, 1491, 1521, ..., 1523, 1533, 1517], dtype=uint16),\n",
       " 'CHELSA_bio18': array([2113, 1993, 2124, ..., 2283, 2103, 1926], dtype=uint16),\n",
       " 'glad_ard_SVVI_min': array([ 347.6654 , -130.54175,  384.52246, ...,  220.32666,  -10.63208,\n",
       "         263.45093], dtype=float32),\n",
       " 'eastness': array([ 0.06909359,  0.26911235, -0.01605454, ..., -0.03627645,\n",
       "         0.02672861, -0.00700016], dtype=float32),\n",
       " 'ORCDRC_WeigAver': array([ 9, 16, 14, ..., 11,  6,  8], dtype=uint16),\n",
       " 'cti': array([-238043120, -208915344, -137479792, ..., -212329056,  140822048,\n",
       "        -227026464], dtype=int32),\n",
       " 'treecover': array([85, 85, 62, ..., 75, 85, 97], dtype=uint8),\n",
       " 'outlet_dist_dw_basin': array([780403, 772777, 898820, ..., 867238, 862879, 812856], dtype=int32),\n",
       " 'glad_ard_SVVI_med': array([ 46.44409 ,  19.552734,  50.743652, ..., 123.39404 , 104.30469 ,\n",
       "        133.24927 ], dtype=float32),\n",
       " 'convergence': array([-10.48656   ,  33.27436   ,   0.04529347, ..., -14.551437  ,\n",
       "         16.743006  ,  -9.116502  ], dtype=float32),\n",
       " 'glad_ard_SVVI_max': array([276.8711  , -49.526367,  93.257324, ..., 377.35132 , 209.16504 ,\n",
       "         27.061035], dtype=float32),\n",
       " 'CECSOL_WeigAver': array([13, 12, 17, ..., 16, 11, 15], dtype=uint16)}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raster_val_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1975cb9d",
   "metadata": {},
   "source": [
    "Create the header of the output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "09043f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['northness', 'forestheight', 'elev', 'CHELSA_bio4', 'SBIO3_Isothermality_5_15cm', 'SBIO4_Temperature_Seasonality_5_15cm', 'dev-magnitude', 'BLDFIE_WeigAver', 'CHELSA_bio18', 'glad_ard_SVVI_min', 'eastness', 'ORCDRC_WeigAver', 'cti', 'treecover', 'outlet_dist_dw_basin', 'glad_ard_SVVI_med', 'convergence', 'glad_ard_SVVI_max', 'CECSOL_WeigAver'])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get keys from dictionary\n",
    "keys = raster_val_dict.keys()\n",
    "keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f6e9ec01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ID Longitude Latitude northness forestheight elev CHELSA_bio4 SBIO3_Isothermality_5_15cm SBIO4_Temperature_Seasonality_5_15cm dev-magnitude BLDFIE_WeigAver CHELSA_bio18 glad_ard_SVVI_min eastness ORCDRC_WeigAver cti treecover outlet_dist_dw_basin glad_ard_SVVI_med convergence glad_ard_SVVI_max CECSOL_WeigAver'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add keys (=field names) to string which starts with \"ID, Longitude and Latitude\"\n",
    "header = f\"ID Longitude Latitude {' '.join(keys)}\"\n",
    "header"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc61578",
   "metadata": {},
   "source": [
    "Create a 2D array with the indixes, coordinates and corresponding raster values for each sampled point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c233500f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all arrays from dictionary as list\n",
    "all_vals = list(raster_val_dict.values())\n",
    "# get index, x-coordinate and y-coordinate as list and add the value arrays to that list\n",
    "all_vals = [np.arange(1, coords.shape[0]+1), coords[:, 0], coords[:, 1]] + all_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7f927f3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1267239, 22)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# stack all arrays to a 2D array\n",
    "all_vals_arr = np.hstack([all_vals]).T\n",
    "all_vals_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d70d02b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00,  6.05000100e+00,  4.97274990e+01,\n",
       "         4.24997807e-02,  2.30000000e+01,  3.53983124e+02,\n",
       "         5.89300000e+03,  1.97989922e+01,  4.40672211e+02,\n",
       "         1.15841722e+00,  1.54000000e+03,  2.11300000e+03,\n",
       "         3.47665405e+02,  6.90935925e-02,  9.00000000e+00,\n",
       "        -2.38043120e+08,  8.50000000e+01,  7.80403000e+05,\n",
       "         4.64440918e+01, -1.04865599e+01,  2.76871094e+02,\n",
       "         1.30000000e+01],\n",
       "       [ 2.00000000e+00,  6.05000170e+00,  4.99221550e+01,\n",
       "         1.82779804e-01,  1.90000000e+01,  2.67511688e+02,\n",
       "         5.91200000e+03,  2.08894119e+01,  4.57756195e+02,\n",
       "        -1.75534081e+00,  1.49100000e+03,  1.99300000e+03,\n",
       "        -1.30541748e+02,  2.69112349e-01,  1.60000000e+01,\n",
       "        -2.08915344e+08,  8.50000000e+01,  7.72777000e+05,\n",
       "         1.95527344e+01,  3.32743607e+01, -4.95263672e+01,\n",
       "         1.20000000e+01],\n",
       "       [ 3.00000000e+00,  6.05000210e+00,  4.86023770e+01,\n",
       "         3.62534299e-02,  2.10000000e+01,  3.89751160e+02,\n",
       "         5.98300000e+03,  2.06958771e+01,  4.81879700e+02,\n",
       "         1.90877986e+00,  1.52100000e+03,  2.12400000e+03,\n",
       "         3.84522461e+02, -1.60545446e-02,  1.40000000e+01,\n",
       "        -1.37479792e+08,  6.20000000e+01,  8.98820000e+05,\n",
       "         5.07436523e+01,  4.52934727e-02,  9.32573242e+01,\n",
       "         1.70000000e+01]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# have a look at the first three rows\n",
    "all_vals_arr[:3, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1affb4",
   "metadata": {},
   "source": [
    "Write the array to a txt-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "37ab730b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the format of each column\n",
    "fmt = '%u %.6f %.6f %u %u %u %u %.6f %i %.8f %.8f %.5f %u %.6f %.6f %.6f %.8f %u %u %.6f %.4f %i'\n",
    "# save\n",
    "np.savetxt('tree_height/txt/eu_x_y_predictors_select_python2.txt', all_vals_arr, fmt=fmt, delimiter=' ', header=header, comments='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e1b90d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# depending on how we process the data, we could also use np.save() to save the array to a binary format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2203cb27",
   "metadata": {},
   "source": [
    "### Stend-alone Python script. By Hannah Weiser"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7892f4ba",
   "metadata": {},
   "source": [
    "\n",
    "    #!/usr/bin/env python\n",
    "    # coding: utf-8\n",
    "\n",
    "    \"\"\"\n",
    "    Modification of the RasterIO Final Script for Preparing the Dataset for the Next ML Exercise \n",
    "\n",
    "    Hannah Weiser, 2023-04-22\n",
    "    \"\"\"\n",
    "\n",
    "    # Imports\n",
    "    from pathlib import Path\n",
    "    import rasterio as rio\n",
    "    import numpy as np\n",
    "    import time\n",
    "\n",
    "    start = time.time()\n",
    "    print(\"Start processing ...\")\n",
    "\n",
    "    # Create a list of (opened) raster datasets and of the corresponding field names\n",
    "    datasets = []\n",
    "    fieldnames = []\n",
    "    for filename in Path('tree_height/geodata_raster/').glob('[!l]*.tif'):\n",
    "        ds = rio.open(filename, mode='r')\n",
    "        datasets.append(ds)\n",
    "        fieldnames.append(filename.stem)\n",
    "\n",
    "    # Read the coordinates to a numpy array\n",
    "    coords = np.genfromtxt('tree_height/txt/eu_x_y_select.txt', delimiter=' ')\n",
    "\n",
    "    # Create a dictionary with an array of pixel values at the coordinates for each field (i.e. values sampled from each raster)\n",
    "    raster_val_dict = {}\n",
    "    for i, ds in enumerate(datasets):\n",
    "        # transform coordinates to raster row and column indices\n",
    "        rows, cols = rio.transform.rowcol(ds.transform, coords[:, 0], coords[:, 1])\n",
    "        rowcols = np.array(list(zip(rows, cols)))\n",
    "        # read band of raster\n",
    "        band = ds.read(1)\n",
    "        # get values by indexing band with row and column indices\n",
    "        vals = np.array([band[row, col] for row, col in rowcols])\n",
    "        # add value array to dictionary\n",
    "        raster_val_dict[fieldnames[i]] = vals\n",
    "        ds.close()\n",
    "\n",
    "    # get keys from dictionary\n",
    "    keys = raster_val_dict.keys()\n",
    "    # add keys (=field names) to string which starts with \"ID, Longitude and Latitude\"\n",
    "    header = f\"ID X Y {' '.join(keys)}\"\n",
    "\n",
    "\n",
    "    # Create a 2D array with the indixes, coordinates and corresponding raster values for each sampled point\n",
    "\n",
    "    # get all arrays from dictionary as list\n",
    "    all_vals = list(raster_val_dict.values())\n",
    "    # get index, x-coordinate and y-coordinate as list and add the value arrays to that list\n",
    "    all_vals = [np.arange(1, coords.shape[0]+1), coords[:, 0], coords[:, 1]] + all_vals\n",
    "\n",
    "    # stack all arrays to a 2D array\n",
    "    all_vals_arr = np.hstack([all_vals]).T\n",
    "\n",
    "    end_operation = time.time()\n",
    "    print(f\"Done in {end_operation-start:.1f} sec., Writing output file...\")\n",
    "\n",
    "    # Write the array to a txt-file\n",
    "\n",
    "    # define the format of each column\n",
    "    fmt = '%u %.6f %.6f %u %u %u %u %.6f %i %.8f %.8f %.5f %u %.6f %.6f %.6f %.8f %u %u %.6f %.4f %i'\n",
    "    # save\n",
    "    np.savetxt('tree_height/txt/eu_x_y_predictors_select_python2.txt', all_vals_arr, fmt=fmt, delimiter=\" \", header=header, comments='')\n",
    "\n",
    "    # depending on how we process the data later on, we could also use np.save() to save the array to a binary format\n",
    "\n",
    "    end = time.time()\n",
    "\n",
    "    print(f\"Done. Writing took {end-end_operation:.1f} sec. Full script took {end-start:.1f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1c33590d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start processing ...\n",
      "Done in 101.4 sec., Writing output file...\n",
      "Done. Writing took 9.7 sec. Full script took 111.2\n",
      "\n",
      "real\t1m51.826s\n",
      "user\t1m21.891s\n",
      "sys\t0m14.028s\n"
     ]
    }
   ],
   "source": [
    "! time python3 /media/sf_LVM_shared/my_SE_data/exercise/Tree_Height_02Predictors_extraction_python2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77676489",
   "metadata": {},
   "source": [
    "    real\t1m51.826s\n",
    "    user\t1m21.891s\n",
    "    sys\t0m14.028s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a369fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
